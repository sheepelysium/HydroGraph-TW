# -*- coding: utf-8 -*-
"""å°‡æ¸¬ç«™è³‡æ–™åŒ¯å…¥ Neo4j çŸ¥è­˜åœ–è­œ (ä½¿ç”¨æœ€è©³ç´°çš„åŸå§‹è³‡æ–™)"""
import pandas as pd
from neo4j import GraphDatabase
from pathlib import Path


class StationImporter:
    """æ¸¬ç«™è³‡æ–™åŒ¯å…¥å™¨"""

    def __init__(self, uri, user, password):
        """åˆå§‹åŒ– Neo4j é€£ç·š"""
        self.driver = GraphDatabase.driver(uri, auth=(user, password))

    def close(self):
        """é—œé–‰é€£ç·š"""
        self.driver.close()

    def create_indexes(self):
        """å»ºç«‹ç´¢å¼•"""
        print("\nå»ºç«‹æ¸¬ç«™ç´¢å¼•...")

        indexes = [
            "CREATE INDEX station_code IF NOT EXISTS FOR (s:Station) ON (s.code)",
            "CREATE INDEX station_name IF NOT EXISTS FOR (s:Station) ON (s.name)",
            "CREATE INDEX station_type IF NOT EXISTS FOR (s:Station) ON (s.type)",
        ]

        with self.driver.session(database="neo4j") as session:
            for idx_query in indexes:
                session.run(idx_query)
                print(f"  [OK] {idx_query.split('FOR')[0].strip()}")

    def import_rainfall_stations(self, excel_path):
        """åŒ¯å…¥é›¨é‡æ¸¬ç«™ (ç¬¬ä¸€å€‹å·¥ä½œè¡¨)

        Args:
            excel_path: æ¸¬ç«™åŸºæœ¬è³‡æ–™2025.xlsx çš„è·¯å¾‘
        """
        print(f"\nè®€å–é›¨é‡æ¸¬ç«™è³‡æ–™ (è©³ç´°ç‰ˆ): {excel_path}")

        # è®€å–ç¬¬ä¸€å€‹å·¥ä½œè¡¨ (é›¨é‡æ¸¬ç«™)
        df = pd.read_excel(excel_path, sheet_name=0)
        print(f"  å…± {len(df)} å€‹é›¨é‡æ¸¬ç«™")
        print(f"  æ¬„ä½: {list(df.columns)}")

        # å»ºç«‹é›¨é‡æ¸¬ç«™ç¯€é»
        print("\nå»ºç«‹é›¨é‡æ¸¬ç«™ç¯€é» (Station:Rainfall)...")

        # å–å¾—å¯¦éš›æ¬„ä½
        cols = list(df.columns)

        with self.driver.session(database="neo4j") as session:
            for idx, row in df.iterrows():
                # é›¨é‡æ¸¬ç«™æ¬„ä½å°æ‡‰:
                # cols[0] = é¡åˆ¥
                # cols[1] = å­˜å»¢ç‹€æ…‹
                # cols[2] = æ¸¬ç«™ä»£è™Ÿ (ç«™è™Ÿ, å¦‚ 2560P008)
                # cols[3] = æ°£è±¡ç½²ç«™è™Ÿ (å¦‚ 01U050)
                # cols[4] = æ¸¬ç«™åç¨± (å¦‚ å£«å ´(1))
                # cols[5] = ç®¡ç†å–®ä½
                # cols[6] = æ°´ç³»
                # cols[7] = æ²³å·
                # cols[8] = é«˜ç¨‹(m)
                # cols[9] = ç¸£å¸‚
                # cols[10] = åœ°å€
                # cols[11-12] = TWD97 åº§æ¨™
                # cols[13] = æ›¿ä»£ç«™è™Ÿ
                # cols[14] = åˆ†é›¨é‡ (æœ‰è³‡æ–™çš„å¹´ä»½)
                # cols[15] = æ™‚é›¨é‡ (æœ‰è³‡æ–™çš„å¹´ä»½)
                # cols[16] = æ—¥é›¨é‡ (æœ‰è³‡æ–™çš„å¹´ä»½)
                # cols[17] = æœˆé›¨é‡ (æœ‰è³‡æ–™çš„å¹´ä»½)
                session.run("""
                    MERGE (s:Station:Rainfall {code: $code})
                    SET s.name = $name,
                        s.type = 'é›¨é‡æ¸¬ç«™',
                        s.category = $category,
                        s.status = $status,
                        s.cwa_station_code = $cwa_station_code,
                        s.management_unit = $management_unit,
                        s.water_system = $water_system,
                        s.river = $river,
                        s.elevation = $elevation,
                        s.city = $city,
                        s.address = $address,
                        s.x_twd97 = $x,
                        s.y_twd97 = $y,
                        s.backup_station_code = $backup_station_code,
                        s.rainfall_minute_years = $rainfall_minute_years,
                        s.rainfall_hour_years = $rainfall_hour_years,
                        s.rainfall_daily_years = $rainfall_daily_years,
                        s.rainfall_monthly_years = $rainfall_monthly_years
                """,
                    code=str(row[cols[2]]) if pd.notna(row[cols[2]]) else None,  # æ¸¬ç«™ä»£è™Ÿ
                    name=str(row[cols[4]]) if pd.notna(row[cols[4]]) else None,  # æ¸¬ç«™åç¨±
                    category=str(row[cols[0]]) if pd.notna(row[cols[0]]) else None,  # é¡åˆ¥
                    status=str(row[cols[1]]) if pd.notna(row[cols[1]]) else None,  # å­˜å»¢ç‹€æ…‹
                    cwa_station_code=str(row[cols[3]]) if pd.notna(row[cols[3]]) else None,  # æ°£è±¡ç½²ç«™è™Ÿ
                    management_unit=str(row[cols[5]]) if pd.notna(row[cols[5]]) else None,  # ç®¡ç†å–®ä½
                    water_system=str(row[cols[6]]) if pd.notna(row[cols[6]]) else None,  # æ°´ç³»
                    river=str(row[cols[7]]) if pd.notna(row[cols[7]]) else None,  # æ²³å·
                    elevation=float(row[cols[8]]) if pd.notna(row[cols[8]]) else None,  # é«˜ç¨‹(m)
                    city=str(row[cols[9]]) if pd.notna(row[cols[9]]) else None,  # ç¸£å¸‚
                    address=str(row[cols[10]]) if pd.notna(row[cols[10]]) else None,  # åœ°å€
                    x=float(row[cols[11]]) if pd.notna(row[cols[11]]) else None,  # TWD97M2(Xåæ¨™)
                    y=float(row[cols[12]]) if pd.notna(row[cols[12]]) else None,  # TWD97M2(Yåæ¨™)
                    backup_station_code=str(row[cols[13]]) if pd.notna(row[cols[13]]) else None,  # æ›¿ä»£ç«™è™Ÿ
                    rainfall_minute_years=str(row[cols[14]]) if pd.notna(row[cols[14]]) else None,  # åˆ†é›¨é‡
                    rainfall_hour_years=str(row[cols[15]]) if pd.notna(row[cols[15]]) else None,  # æ™‚é›¨é‡
                    rainfall_daily_years=str(row[cols[16]]) if pd.notna(row[cols[16]]) else None,  # æ—¥é›¨é‡
                    rainfall_monthly_years=str(row[cols[17]]) if pd.notna(row[cols[17]]) else None  # æœˆé›¨é‡
                )

                if (idx + 1) % 50 == 0:
                    print(f"  å·²åŒ¯å…¥ {idx + 1}/{len(df)} å€‹é›¨é‡æ¸¬ç«™...")

        print(f"[OK] å·²åŒ¯å…¥ {len(df)} å€‹é›¨é‡æ¸¬ç«™")

    def import_water_level_stations(self, excel_path):
        """åŒ¯å…¥æ°´ä½æ¸¬ç«™ (ç¬¬äºŒå€‹å·¥ä½œè¡¨)

        Args:
            excel_path: æ¸¬ç«™åŸºæœ¬è³‡æ–™2025.xlsx çš„è·¯å¾‘
        """
        print(f"\nè®€å–æ°´ä½æ¸¬ç«™è³‡æ–™ (è©³ç´°ç‰ˆ)...")

        # è®€å–ç¬¬äºŒå€‹å·¥ä½œè¡¨ (æ°´ä½æ¸¬ç«™)
        df = pd.read_excel(excel_path, sheet_name=1)
        print(f"  å…± {len(df)} å€‹æ°´ä½æ¸¬ç«™")
        print(f"  æ¬„ä½: {list(df.columns)}")

        # å»ºç«‹æ°´ä½æ¸¬ç«™ç¯€é»
        print("\nå»ºç«‹æ°´ä½æ¸¬ç«™ç¯€é» (Station:WaterLevel)...")

        # å–å¾—å¯¦éš›æ¬„ä½
        cols = list(df.columns)

        with self.driver.session(database="neo4j") as session:
            for idx, row in df.iterrows():
                # æ°´ä½æ¸¬ç«™æ¬„ä½å°æ‡‰ (æ²’æœ‰æ°£è±¡ç½²ç«™è™Ÿ,æ¯”é›¨é‡ç«™å°‘1æ¬„):
                # cols[0] = é¡åˆ¥
                # cols[1] = å­˜å»¢ç‹€æ…‹
                # cols[2] = ç«™è™Ÿ (æ¸¬ç«™ä»£è™Ÿ)
                # cols[3] = ç«™å (æ¸¬ç«™åç¨±)
                # cols[4] = ç®¡ç†å–®ä½
                # cols[5] = æµåŸŸ
                # cols[6] = æ²³å·
                # cols[7] = é«˜ç¨‹(m)
                # cols[8] = ç¸£å¸‚
                # cols[9] = åœ°å€
                # cols[10-11] = TWD97 åº§æ¨™
                # cols[12] = æ›¿ä»£ç«™è™Ÿ
                # cols[13] = æ™‚æ°´ä½ (æœ‰è³‡æ–™çš„å¹´ä»½)
                # cols[14] = æ—¥æ°´ä½ (æœ‰è³‡æ–™çš„å¹´ä»½)
                # cols[15] = æœˆæ°´ä½ (æœ‰è³‡æ–™çš„å¹´ä»½)
                # cols[16] = æ™‚æµé‡ (æœ‰è³‡æ–™çš„å¹´ä»½)
                # cols[17] = æ—¥æµé‡ (æœ‰è³‡æ–™çš„å¹´ä»½)
                # cols[18] = æœˆæµé‡ (æœ‰è³‡æ–™çš„å¹´ä»½)
                # cols[19] = å«ç ‚é‡åŠå¯¦æ¸¬æµé‡ (æœ‰è³‡æ–™çš„å¹´ä»½)
                session.run("""
                    MERGE (s:Station:WaterLevel {code: $code})
                    SET s.name = $name,
                        s.type = 'æ°´ä½æ¸¬ç«™',
                        s.category = $category,
                        s.status = $status,
                        s.management_unit = $management_unit,
                        s.water_system = $water_system,
                        s.river = $river,
                        s.elevation = $elevation,
                        s.city = $city,
                        s.address = $address,
                        s.x_twd97 = $x,
                        s.y_twd97 = $y,
                        s.backup_station_code = $backup_station_code,
                        s.water_level_hour_years = $water_level_hour_years,
                        s.water_level_daily_years = $water_level_daily_years,
                        s.water_level_monthly_years = $water_level_monthly_years,
                        s.flow_hour_years = $flow_hour_years,
                        s.flow_daily_years = $flow_daily_years,
                        s.flow_monthly_years = $flow_monthly_years,
                        s.sediment_years = $sediment_years
                """,
                    code=str(row[cols[2]]) if pd.notna(row[cols[2]]) else None,  # ç«™è™Ÿ
                    name=str(row[cols[3]]) if pd.notna(row[cols[3]]) else None,  # ç«™å
                    category=str(row[cols[0]]) if pd.notna(row[cols[0]]) else None,  # é¡åˆ¥
                    status=str(row[cols[1]]) if pd.notna(row[cols[1]]) else None,  # å­˜å»¢ç‹€æ…‹
                    management_unit=str(row[cols[4]]) if pd.notna(row[cols[4]]) else None,  # ç®¡ç†å–®ä½
                    water_system=str(row[cols[5]]) if pd.notna(row[cols[5]]) else None,  # æµåŸŸ
                    river=str(row[cols[6]]) if pd.notna(row[cols[6]]) else None,  # æ²³å·
                    elevation=float(row[cols[7]]) if pd.notna(row[cols[7]]) else None,  # é«˜ç¨‹(m)
                    city=str(row[cols[8]]) if pd.notna(row[cols[8]]) else None,  # ç¸£å¸‚
                    address=str(row[cols[9]]) if pd.notna(row[cols[9]]) else None,  # åœ°å€
                    x=float(row[cols[10]]) if pd.notna(row[cols[10]]) else None,  # TWD97M2(Xåæ¨™)
                    y=float(row[cols[11]]) if pd.notna(row[cols[11]]) else None,  # TWD97M2(Yåæ¨™)
                    backup_station_code=str(row[cols[12]]) if pd.notna(row[cols[12]]) else None,  # æ›¿ä»£ç«™è™Ÿ
                    water_level_hour_years=str(row[cols[13]]) if pd.notna(row[cols[13]]) else None,  # æ™‚æ°´ä½
                    water_level_daily_years=str(row[cols[14]]) if pd.notna(row[cols[14]]) else None,  # æ—¥æ°´ä½
                    water_level_monthly_years=str(row[cols[15]]) if pd.notna(row[cols[15]]) else None,  # æœˆæ°´ä½
                    flow_hour_years=str(row[cols[16]]) if pd.notna(row[cols[16]]) else None,  # æ™‚æµé‡
                    flow_daily_years=str(row[cols[17]]) if pd.notna(row[cols[17]]) else None,  # æ—¥æµé‡
                    flow_monthly_years=str(row[cols[18]]) if pd.notna(row[cols[18]]) else None,  # æœˆæµé‡
                    sediment_years=str(row[cols[19]]) if pd.notna(row[cols[19]]) else None  # å«ç ‚é‡åŠå¯¦æ¸¬æµé‡
                )

                if (idx + 1) % 50 == 0:
                    print(f"  å·²åŒ¯å…¥ {idx + 1}/{len(df)} å€‹æ°´ä½æ¸¬ç«™...")

        print(f"[OK] å·²åŒ¯å…¥ {len(df)} å€‹æ°´ä½æ¸¬ç«™")

    def link_stations_to_rivers(self, matching_report_path):
        """å»ºç«‹æ¸¬ç«™ -> æ²³å·é—œä¿‚ (ä½¿ç”¨é…å°å ±è¡¨ï¼ŒåŠ å…¥ä»£ç¢¼é©—è­‰é¿å…åŒåæ²³å·éŒ¯èª¤é…å°)

        Args:
            matching_report_path: æ¸¬ç«™æ²³å·é…å°åˆ†æå ±è¡¨.xlsx çš„è·¯å¾‘
        """
        print(f"\nå»ºç«‹æ¸¬ç«™ MONITORS æ²³å·é—œä¿‚...")

        # è®€å–ã€Œèƒ½é…å°çš„æ¸¬ç«™ã€å·¥ä½œè¡¨
        df = pd.read_excel(matching_report_path, sheet_name='èƒ½é…å°çš„æ¸¬ç«™')
        print(f"  å…± {len(df)} å€‹èƒ½é…å°çš„æ¸¬ç«™")

        # å–å¾—æ¬„ä½åˆ—è¡¨
        cols = list(df.columns)

        with self.driver.session(database="neo4j") as session:
            count = 0
            skipped = 0
            code_mismatch = 0

            for idx, row in df.iterrows():
                # æ›´æ–°å¾Œçš„æ¬„ä½çµæ§‹:
                # cols[0] = æ¸¬ç«™é¡å‹
                # cols[1] = æ¸¬ç«™ä»£è™Ÿ
                # cols[2] = æ¸¬ç«™åç¨±
                # cols[3] = æ²³å·
                # cols[4] = åŒ¹é…çš„æ²³å·
                # cols[5] = æ²³å·ä»£ç¢¼
                # cols[6] = åŒ¹é…æ–¹å¼
                # cols[7] = ç®¡ç†å–®ä½
                # cols[8] = é«˜ç¨‹(m)

                station_code = str(row[cols[1]]).strip() if pd.notna(row[cols[1]]) and str(row[cols[1]]).strip() != '' else None
                river_code = str(row[cols[5]]) if pd.notna(row[cols[5]]) else None

                if station_code and river_code:
                    # â˜… ä»£ç¢¼é©—è­‰: æ¸¬ç«™ä»£ç¢¼å‰ç¶´æ‡‰èˆ‡æ²³å·ä»£ç¢¼å‰ç¶´åŒ¹é…
                    # é¿å…åŒåæ²³å·éŒ¯èª¤é…å° (ä¾‹å¦‚: åŒ—æ¸¯æºªåœ¨æ·¡æ°´æ²³å’Œé›²æ—éƒ½æœ‰)
                    station_prefix_4 = station_code[:4]
                    river_prefix_4 = river_code[:4]
                    station_prefix_3 = station_code[:3]
                    river_prefix_3 = river_code[:3]

                    if station_prefix_4 != river_prefix_4 and station_prefix_3 != river_prefix_3:
                        # ä»£ç¢¼ä¸åŒ¹é…ï¼Œè·³éæ­¤é…å°
                        code_mismatch += 1
                        continue

                    # ä½¿ç”¨æ¸¬ç«™ä»£è™Ÿä¾†åŒ¹é…,éœ€è¦è™•ç†Neo4jä¸­å¯èƒ½çš„å°¾éš¨ç©ºæ ¼
                    session.run("""
                        MATCH (s:Station)
                        WHERE trim(s.code) = $station_code
                        MATCH (r:River {code: $river_code})
                        MERGE (s)-[rel:MONITORS]->(r)
                        SET rel.match_type = $match_type,
                            rel.original_river_name = $original_river,
                            rel.matched_river_name = $matched_river
                    """,
                        station_code=station_code,
                        river_code=river_code,
                        match_type=str(row[cols[6]]) if pd.notna(row[cols[6]]) else 'unknown',
                        original_river=str(row[cols[3]]) if pd.notna(row[cols[3]]) else None,
                        matched_river=str(row[cols[4]]) if pd.notna(row[cols[4]]) else None
                    )
                    count += 1
                else:
                    skipped += 1

                if (idx + 1) % 100 == 0:
                    print(f"  å·²è™•ç† {idx + 1}/{len(df)} æ¢...")

        print(f"[OK] å·²å»ºç«‹ {count} æ¢æ¸¬ç«™-æ²³å·é—œä¿‚")
        if skipped > 0:
            print(f"[INFO] è·³é {skipped} æ¢ (ç¼ºå°‘æ¸¬ç«™ä»£è™Ÿæˆ–æ²³å·ä»£ç¢¼)")
        if code_mismatch > 0:
            print(f"[INFO] éæ¿¾ {code_mismatch} æ¢ä»£ç¢¼ä¸åŒ¹é… (é¿å…åŒåæ²³å·éŒ¯èª¤é…å°)")

    def link_stations_to_watersheds(self):
        """å»ºç«‹æ¸¬ç«™ -> é›†æ°´å€é—œä¿‚ (æ ¹æ“šé›†æ°´å€åç¨±)"""
        print("\nå»ºç«‹æ¸¬ç«™ LOCATED_IN é›†æ°´å€é—œä¿‚...")

        with self.driver.session(database="neo4j") as session:
            # ä½¿ç”¨æ¸¬ç«™çš„ watershed å±¬æ€§èˆ‡é›†æ°´å€çš„ name å±¬æ€§é…å°
            result = session.run("""
                MATCH (s:Station)
                WHERE s.watershed IS NOT NULL
                MATCH (w:Watershed)
                WHERE w.name = s.watershed
                MERGE (s)-[:LOCATED_IN]->(w)
                RETURN count(*) as count
            """)

            count = result.single()["count"]

        print(f"[OK] å·²å»ºç«‹ {count} æ¢æ¸¬ç«™-é›†æ°´å€é—œä¿‚")

    def verify_import(self):
        """é©—è­‰åŒ¯å…¥çµæœ"""
        print("\n" + "="*80)
        print("é©—è­‰æ¸¬ç«™åŒ¯å…¥çµæœ")
        print("="*80)

        with self.driver.session(database="neo4j") as session:
            # çµ±è¨ˆç¯€é»æ•¸é‡
            total_stations = session.run(
                "MATCH (s:Station) RETURN count(s) as count"
            ).single()["count"]

            rainfall = session.run(
                "MATCH (s:Rainfall) RETURN count(s) as count"
            ).single()["count"]

            water_level = session.run(
                "MATCH (s:WaterLevel) RETURN count(s) as count"
            ).single()["count"]

            print(f"\nç¯€é»çµ±è¨ˆ:")
            print(f"  Station ç¸½æ•¸: {total_stations}")
            print(f"    - Rainfall (é›¨é‡æ¸¬ç«™): {rainfall}")
            print(f"    - WaterLevel (æ°´ä½æ¸¬ç«™): {water_level}")

            # çµ±è¨ˆé—œä¿‚æ•¸é‡
            monitors_count = session.run(
                "MATCH ()-[r:MONITORS]->() RETURN count(r) as count"
            ).single()["count"]

            located_in_count = session.run(
                "MATCH ()-[r:LOCATED_IN]->() RETURN count(r) as count"
            ).single()["count"]

            print(f"\né—œä¿‚çµ±è¨ˆ:")
            print(f"  MONITORS (ç›£æ¸¬æ²³å·): {monitors_count}")
            print(f"  LOCATED_IN (ä½æ–¼é›†æ°´å€): {located_in_count}")

            # æŒ‰ç®¡ç†å–®ä½çµ±è¨ˆ
            print(f"\næ¸¬ç«™ç®¡ç†å–®ä½åˆ†å¸ƒ (å‰10):")
            result = session.run("""
                MATCH (s:Station)
                WHERE s.management_unit IS NOT NULL
                RETURN s.management_unit as unit, count(s) as count
                ORDER BY count DESC
                LIMIT 10
            """)

            for record in result:
                print(f"  - {record['unit']}: {record['count']} å€‹æ¸¬ç«™")

            # é¡¯ç¤ºæœ‰åº§æ¨™çš„æ¸¬ç«™æ¯”ä¾‹
            with_coords = session.run("""
                MATCH (s:Station)
                WHERE s.x_twd97 IS NOT NULL AND s.y_twd97 IS NOT NULL
                RETURN count(s) as count
            """).single()["count"]

            print(f"\nåº§æ¨™è³‡æ–™å®Œæ•´åº¦:")
            print(f"  æœ‰åº§æ¨™çš„æ¸¬ç«™: {with_coords}/{total_stations} "
                  f"({with_coords/total_stations*100:.1f}%)")

            # é¡¯ç¤ºç¯„ä¾‹é›¨é‡æ¸¬ç«™
            print(f"\nç¯„ä¾‹é›¨é‡æ¸¬ç«™ (å‰5å€‹):")
            result = session.run("""
                MATCH (s:Rainfall)-[:MONITORS]->(r:River)
                RETURN s.name as station, s.river as river_in_station,
                       r.name as matched_river, s.elevation as elevation
                LIMIT 5
            """)

            for record in result:
                print(f"  - {record['station']} (é«˜ç¨‹{record['elevation']}m) â†’ "
                      f"{record['matched_river']}")

            # é¡¯ç¤ºç¯„ä¾‹æ°´ä½æ¸¬ç«™
            print(f"\nç¯„ä¾‹æ°´ä½æ¸¬ç«™ (å‰5å€‹):")
            result = session.run("""
                MATCH (s:WaterLevel)
                RETURN s.name as station, s.watershed as watershed,
                       s.city as city, s.elevation as elevation
                LIMIT 5
            """)

            for record in result:
                print(f"  - {record['station']} ({record['city']}, "
                      f"é«˜ç¨‹{record['elevation']}m) â†’ {record['watershed']}")


def main():
    """ä¸»ç¨‹å¼"""
    print("="*80)
    print("æ¸¬ç«™è³‡æ–™åŒ¯å…¥ Neo4j (è©³ç´°ç‰ˆ)")
    print("="*80)

    # Neo4j é€£ç·šè¨­å®š
    NEO4J_URI = "bolt://localhost:7687"
    NEO4J_USER = "neo4j"
    NEO4J_PASSWORD = "geoinfor"  # è«‹æ”¹æˆæ‚¨çš„å¯†ç¢¼

    # è³‡æ–™æª”æ¡ˆè·¯å¾‘
    STATION_DATA_PATH = Path("data/æ¸¬ç«™åŸºæœ¬è³‡æ–™2025.xlsx")
    MATCHING_REPORT_PATH = Path("data/æ¸¬ç«™æ²³å·é…å°åˆ†æå ±è¡¨.xlsx")

    # ç¢ºèªæª”æ¡ˆå­˜åœ¨
    if not STATION_DATA_PATH.exists():
        print(f"[X] æ‰¾ä¸åˆ°æª”æ¡ˆ: {STATION_DATA_PATH}")
        return

    if not MATCHING_REPORT_PATH.exists():
        print(f"[X] æ‰¾ä¸åˆ°æª”æ¡ˆ: {MATCHING_REPORT_PATH}")
        return

    # å»ºç«‹åŒ¯å…¥å™¨
    importer = StationImporter(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)

    try:
        # å»ºç«‹ç´¢å¼•
        importer.create_indexes()

        # åŒ¯å…¥é›¨é‡æ¸¬ç«™ (ç¬¬ä¸€å€‹å·¥ä½œè¡¨)
        importer.import_rainfall_stations(STATION_DATA_PATH)

        # åŒ¯å…¥æ°´ä½æ¸¬ç«™ (ç¬¬äºŒå€‹å·¥ä½œè¡¨)
        importer.import_water_level_stations(STATION_DATA_PATH)

        # å»ºç«‹æ¸¬ç«™ -> æ²³å·é—œä¿‚
        importer.link_stations_to_rivers(MATCHING_REPORT_PATH)

        # å»ºç«‹æ¸¬ç«™ -> é›†æ°´å€é—œä¿‚
        importer.link_stations_to_watersheds()

        # é©—è­‰çµæœ
        importer.verify_import()

        print("\n" + "="*80)
        print("[OK] æ¸¬ç«™è³‡æ–™åŒ¯å…¥å®Œæˆ!")
        print("="*80)
        print("\nğŸ’¡ æç¤º: è«‹ç¢ºä¿å·²å…ˆåŸ·è¡Œ:")
        print("   - 5_import_rivers_to_neo4j.py (æ²³å·è³‡æ–™)")
        print("   - 6_import_watersheds_to_neo4j.py (é›†æ°´å€è³‡æ–™)")

    except Exception as e:
        print(f"\n[X] ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

    finally:
        importer.close()
        print("\nå·²é—œé–‰ Neo4j é€£ç·š")


if __name__ == "__main__":
    main()
